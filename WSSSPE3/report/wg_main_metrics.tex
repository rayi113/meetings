%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Useful Metrics for Scientific Software}
\label{sec:software-metrics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Why it is important}

Metrics for scientific software are important for tenure and promotion, scientific impact, discovery, reducing duplication, serving as a basis for potential industrial interest in adopting software, and making a case for new or continued funding.  However, there is no commonly-used standard for collecting or presenting metrics, nor is it known if there is a common set of metrics for scientific software.  It is imperative that scientific software stakeholders understand that it is useful to collect metrics.

\subsubsection{Fit with related activities}

The group discussion here focused on identifying existing frameworks and activities for scientific software metrics.  The group identified the following related activities:

\begin{itemize}

\item
\href{https://geodynamics.org/cig/dev/best-practices/}{(Computational Infrastructure for Geodynamics: Software Development Best Practices)}

\item
\href{https://docs.google.com/document/d/1cgUDH3RxrfsLotWhKKOrXUnaYFhrtjcV1TDRkFtwQKI/edit}{(WSSSPE3 Breakout Session: How can we measure the impact of a code on research, and its value to the community?)}

\item
\href{https://docs.google.com/document/d/10yj7MYEjvrg__t522XR41ogASYMp647-l-BpFTsqEV4/edit#heading=h.5lah0hp73q99}{(2015 NSF SI2 PI Workshop Breakout Session on Framing Success Metrics)}

\item
\href{https://docs.google.com/document/d/1uDim5bw8rBuubmtaUrz5Eh35NxzDgivmmdXhVzDs3tc/edit}{(2015 NSF SI2 PI Workshop Breakout Session on Software Metrics)}

\item
\href{https://docs.google.com/presentation/d/1PPLVL6uoOmisqnHTlwhsVKJBTFFK1IVzvr8FdEEIvAE/edit#slide=id.g5e66ec9f2_027}{(NSF Workshop on Software and Data Citation Breakout Group on Useful Metrics)}

\item
\href{http://www.software.ac.uk/software-evaluation-guide}{(U.K. Software Sustainability Institute Software Evaluation Guide)}

\item
\href{http://www.software.ac.uk/blog/2013-04-09-five-stars-research-software}{(U.K. Software Sustainability Institute Blog post: The five stars of research software)}

\item
\href{http://figshare.com/articles/Minimal_information_for_reusable_scientific_software/1112528}{(Minimal information for reusable scientific software)}

\item
\href{http://equipment.data.ac.uk/}{(EPSRC-funded Equipment Data Search Site)}

\item
\href{http://www.canarie.ca/software/}{(Canarie Research Software: Software to accelerate discovery)}

\item
\href{https://science.canarie.ca/researchmiddleware/platforms/list/main.html}{(Canarie Research Software: Research Software Platform Registry)}

\item
\href{https://collaboration.canarie.ca/elgg/file/view/2471/research-platform-support-for-the-canarie-registry-and-monitoring-system-revision-3}{(collaboration@CANARIE post: platform support for Canarie registry and monitoring system)}

\item
\href{https://collaboration.canarie.ca/elgg/file/view/2453/research-service-support-for-canarie-registry-and-monitoring-system-revision-7}{(collaboration@CANARIE post: service support for Canarie registry and monitoring system)}

\item
\href{https://www.openhub.net/}{(BlackDuck Open HUB)}

\item
\href{https://www.innovationpolicyplatform.org/frontpage}{(Innovation Policy Platform)}


\end{itemize}



\subsubsection{Discussion}

The group discussion began by agreeing on the common purpose of creating a set of guidance giving examples of specific metrics for the success of scientific software in use, why they were chosen, what they are useful to measure, and any challenges and pitfalls; then publish this as a white paper.  The group discussed many questions related to useful metrics for scientific software including addressing if there is a common set of metrics that can be filtered in some way, can metrics be fit into a common template, which metrics would be the most useful for each stakeholder, which metrics are the most helpful and how would we assess this, how are metrics monitored, and many more.  A more complete bulleted list of these questions can be found in Appendix H.  Next, a roadmap for how to proceed was discussed including creating a set of milestones and tasks.  The idea was put forth for the group to interact with the organizing committee of the 2016 NSF Software Infrastructure for Sustained Innovation (SI2) PI workshop in order to email out a software metrics survey to all SI2 and related awardees as a targeted and relevant set of stakeholders.  This survey would be created by one of the student group members.  Similarly, it was suggested that a software metrics survey be sent to the UK SFTF and TRDF software projects to ask them what metrics would be useful to report.  The remainder of the discussion focused mainly on the creation of a white paper on this topic.  This resulted in a paper outline and writing assignments with the goal of publishing in venues including WSSSPE4, IEEE CISE, or JORS.

\subsubsection{Plans}

The main plans for the group going forward are the creation of a white paper on the topic of useful metrics for scientific software.  The authoring of this white paper would happen in parallel with the creation of a survey by the group with the survey results to be incorporated in the white paper.  The timeline for completion of the white paper is approximately one year targeting venues discussed in the previous section.

\subsubsection{Landing Page}

The group will use Google Docs to proceed with the authoring of the white paper in lieu of a group project landing page.  Links to the resulting white paper will be provided when completed.

